{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46edb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ed7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "DATA_RAW = Path(\"./\")\n",
    "SRC = DATA_RAW / \"fvqa\" / \"new_dataset_release/images\"\n",
    "DST = Path(\"../data\") / \"images\" / \"fvqa\"\n",
    "\n",
    "if not SRC.exists():\n",
    "    raise FileNotFoundError(str(SRC))\n",
    "\n",
    "if DST.exists():\n",
    "    print(f\"Destination exists, skipping: {DST}\")\n",
    "else:\n",
    "    DST.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree(SRC, DST)\n",
    "    print(f\"Copied folder: {SRC} -> {DST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cebb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(\"./\")\n",
    "FVQA_DIR = DATA_ROOT / \"fvqa\"\n",
    "IMG_DIR = FVQA_DIR / \"Images\"\n",
    "QS_JSON = FVQA_DIR / \"new_dataset_release\" / \"all_qs_dict_release.json\"\n",
    "SPLIT_DIR = FVQA_DIR / \"Name_Lists\"\n",
    "def load_split_list(path):\n",
    "    if not path.exists():\n",
    "        return set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return {line.strip() for line in f if line.strip()}\n",
    "\n",
    "SPLIT_FILES = {\n",
    "    \"train\": SPLIT_DIR / \"train_list_0.txt\",\n",
    "    \"val\": SPLIT_DIR / \"val_list_0.txt\", \n",
    "    \"test\": SPLIT_DIR / \"test_list_0.txt\",\n",
    "}\n",
    "split_sets = {k: load_split_list(v) for k, v in SPLIT_FILES.items()}\n",
    "\n",
    "with open(QS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    qs_dict = json.load(f)\n",
    "\n",
    "def record_to_row(rec):\n",
    "    return {\n",
    "        \"image_path\": str(IMG_DIR / rec.get(\"img_file\", \"\")),\n",
    "        \"question\": rec.get(\"question\", \"\"),\n",
    "        \"answer\": rec.get(\"answer\", \"\"),\n",
    "        \"rationale\": rec.get(\"fact_surface\", \"\"),\n",
    "        \"choices\": \"\",\n",
    "    }\n",
    "\n",
    "rows_by_split = {\"train\": [], \"val\": [], \"test\": []}\n",
    "for rec in qs_dict.values():\n",
    "    img = rec.get(\"img_file\", \"\")\n",
    "    if img in split_sets[\"test\"]:\n",
    "        split = \"test\"\n",
    "    elif img in split_sets[\"val\"]:\n",
    "        split = \"val\"\n",
    "    elif img in split_sets[\"train\"]:\n",
    "        split = \"train\"\n",
    "    else:\n",
    "        split = \"train\"\n",
    "    rows_by_split[split].append(record_to_row(rec))\n",
    "\n",
    "# df_train = pd.DataFrame(rows_by_split[\"train\"], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n",
    "# df_val = pd.DataFrame(rows_by_split[\"val\"], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n",
    "# df_test = pd.DataFrame(rows_by_split[\"test\"], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f62773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def map_image_path(p):\n",
    "    s = str(p)\n",
    "    s = s.replace(\"fvqa/Images\", \"data/image/fvqa\").replace(\"fvqa/images\", \"data/image/fvqa\")\n",
    "    return s\n",
    "\n",
    "def clean_rationale(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    t = str(text).replace(\"[[\", \"\").replace(\"]]\", \"\")\n",
    "    t = re.sub(r\"[^A-Za-z0-9\\s\\.,!?;:'\\\"()\\-/]\", \"\", t)  # remove special chars like *\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    if not t.endswith(\".\"):\n",
    "        t = t.rstrip(\".\") + \".\"\n",
    "    return t\n",
    "\n",
    "def build_df(rows_by_split, split):\n",
    "    df = pd.DataFrame(rows_by_split[split], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n",
    "    df[\"image_path\"] = df[\"image_path\"].apply(map_image_path)\n",
    "    df[\"rationale\"] = df[\"rationale\"].apply(clean_rationale)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bafdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = build_df(rows_by_split, \"train\")\n",
    "df_test = build_df(rows_by_split, \"test\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.image_path.nunique())\n",
    "# print(df_val.image_path.nunique())\n",
    "print(df_test.image_path.nunique())\n",
    "# count files under ../data/images/fvqa\n",
    "len(list(Path(\"../data/images/fvqa\").glob(\"*.JPEG\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_DIR = FVQA_DIR / \"parquet\"\n",
    "PARQUET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train.to_parquet(PARQUET_DIR / \"train.parquet\", index=False)\n",
    "# df_val.to_parquet(PARQUET_DIR / \"val.parquet\", index=False)\n",
    "df_test.to_parquet(PARQUET_DIR / \"test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32025c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokens import HF_TOKEN\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder, upload_file\n",
    "from huggingface_hub.utils import disable_progress_bars\n",
    "disable_progress_bars()\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "repo_id = \"JJoy333/RationaleVQA\"\n",
    "create_repo(repo_id=repo_id, repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=str(PARQUET_DIR),\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    path_in_repo=\"FVQA\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519eec96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
