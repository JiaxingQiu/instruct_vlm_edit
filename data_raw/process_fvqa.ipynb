{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46edb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ed7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "DATA_RAW = Path(\"./\")\n",
    "SRC = DATA_RAW / \"fvqa\" / \"new_dataset_release/images\"\n",
    "DST = Path(\"../data\") / \"images\" / \"fvqa\"\n",
    "\n",
    "if not SRC.exists():\n",
    "    raise FileNotFoundError(str(SRC))\n",
    "\n",
    "if DST.exists():\n",
    "    print(f\"Destination exists, skipping: {DST}\")\n",
    "else:\n",
    "    DST.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree(SRC, DST)\n",
    "    print(f\"Copied folder: {SRC} -> {DST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cebb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(\"./\")\n",
    "FVQA_DIR = DATA_ROOT / \"fvqa\"\n",
    "IMG_DIR = FVQA_DIR / \"Images\"\n",
    "QS_JSON = FVQA_DIR / \"new_dataset_release\" / \"all_qs_dict_release.json\"\n",
    "SPLIT_DIR = FVQA_DIR / \"Name_Lists\"\n",
    "def load_split_list(path):\n",
    "    if not path.exists():\n",
    "        return set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return {line.strip() for line in f if line.strip()}\n",
    "\n",
    "SPLIT_FILES = {\n",
    "    \"train\": SPLIT_DIR / \"train_list_0.txt\",\n",
    "    \"val\": SPLIT_DIR / \"val_list_0.txt\", \n",
    "    \"test\": SPLIT_DIR / \"test_list_0.txt\",\n",
    "}\n",
    "split_sets = {k: load_split_list(v) for k, v in SPLIT_FILES.items()}\n",
    "\n",
    "with open(QS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    qs_dict = json.load(f)\n",
    "\n",
    "def record_to_row(rec):\n",
    "    return {\n",
    "        \"image_path\": str(IMG_DIR / rec.get(\"img_file\", \"\")),\n",
    "        \"question\": rec.get(\"question\", \"\"),\n",
    "        \"answer\": rec.get(\"answer\", \"\"),\n",
    "        \"rationale\": rec.get(\"fact_surface\", \"\"),\n",
    "        \"choices\": \"\",\n",
    "    }\n",
    "\n",
    "rows_by_split = {\"train\": [], \"val\": [], \"test\": []}\n",
    "for rec in qs_dict.values():\n",
    "    img = rec.get(\"img_file\", \"\")\n",
    "    if img in split_sets[\"test\"]:\n",
    "        split = \"test\"\n",
    "    elif img in split_sets[\"val\"]:\n",
    "        split = \"val\"\n",
    "    elif img in split_sets[\"train\"]:\n",
    "        split = \"train\"\n",
    "    else:\n",
    "        split = \"train\"\n",
    "    rows_by_split[split].append(record_to_row(rec))\n",
    "\n",
    "# df_train = pd.DataFrame(rows_by_split[\"train\"], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n",
    "# df_val = pd.DataFrame(rows_by_split[\"val\"], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n",
    "# df_test = pd.DataFrame(rows_by_split[\"test\"], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f62773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def map_image_path(p):\n",
    "    s = str(p)\n",
    "    s = s.replace(\"fvqa/Images\", \"data/images/fvqa\").replace(\"fvqa/images\", \"data/images/fvqa\")\n",
    "    return s\n",
    "\n",
    "def clean_rationale(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    t = str(text).replace(\"[[\", \"\").replace(\"]]\", \"\")\n",
    "    t = re.sub(r\"[^A-Za-z0-9\\s\\.,!?;:'\\\"()\\-/]\", \"\", t)  # remove special chars like *\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    if not t.endswith(\".\"):\n",
    "        t = t.rstrip(\".\") + \".\"\n",
    "    return t\n",
    "\n",
    "def build_df(rows_by_split, split):\n",
    "    df = pd.DataFrame(rows_by_split[split], columns=[\"image_path\", \"question\", \"answer\", \"rationale\", \"choices\"])\n",
    "    df[\"image_path\"] = df[\"image_path\"].apply(map_image_path)\n",
    "    df[\"rationale\"] = df[\"rationale\"].apply(clean_rationale)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bafdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = build_df(rows_by_split, \"train\")\n",
    "df_val = build_df(rows_by_split, \"val\")\n",
    "df_test = build_df(rows_by_split, \"test\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.image_path.nunique())\n",
    "print(df_val.image_path.nunique())\n",
    "print(df_test.image_path.nunique())\n",
    "# count files under ../data/images/fvqa\n",
    "len(list(Path(\"../data/images/fvqa\").glob(\"*.JPEG\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a232ec",
   "metadata": {},
   "source": [
    "# GPT4o-mini \n",
    "generate negative samples B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openai\n",
    "import os, json, random\n",
    "from openai import OpenAI           # pip install --upgrade openai\n",
    "from tokens import openai_key\n",
    "client = OpenAI(api_key=openai_key)\n",
    "MODEL_NAME = \"4o-mini\"          # official public model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fe94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _clean_item(s: str) -> str:\n",
    "    # Only strip bullet formats like \"(A)\", \"A.\", \"A)\", not words starting with A-D\n",
    "    s = re.sub(r\"^\\s*\\([A-Da-d]\\)\\.?\\s*\", \"\", s.strip())  # strip (A), (B), etc.\n",
    "    s = re.sub(r\"^\\s*[A-Da-d]\\.\\s*\", \"\", s.strip())  # strip \"A.\", \"B.\", etc.\n",
    "    s = re.sub(r\"^\\s*[\\-\\*\\[\\]]\\s*\", \"\", s.strip())  # strip bullets like \"-\", \"*\", \"[\", \"]\"\n",
    "    s = s.strip().strip('\"').strip(\"'\")\n",
    "    return s\n",
    "\n",
    "def generate_distractors(client: OpenAI, question: str, correct: str, n: int = 3, model: str = None, temperature: float = 0.2, max_retries: int = 3) -> List[str]:\n",
    "    \"\"\"Return n wrong answers (strings) for the given question, distinct from correct.\"\"\"\n",
    "    model = model or MODEL_NAME\n",
    "    prompt = (\n",
    "        f\"Generate {n} different incorrect answers to the question: {question}\\n\"\n",
    "        f\"They must be different from the correct answer: {correct}\\n\"\n",
    "        f\"Each answer should be a short word or phrase. \"\n",
    "        f\"Return them as a single line joined by the '|' character only.\"\n",
    "    )\n",
    "    backoff = 1.0\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature,\n",
    "                max_tokens=80,\n",
    "            )\n",
    "            text = resp.choices[0].message.content.strip()\n",
    "            parts = [p for p in (seg.strip() for seg in text.split(\"|\")) if p]\n",
    "            parts = [_clean_item(p) for p in parts]\n",
    "            # de-dup, filter out the correct answer\n",
    "            uniq = []\n",
    "            for p in parts:\n",
    "                if p and p.lower() != str(correct).lower() and p not in uniq:\n",
    "                    uniq.append(p)\n",
    "            # pad if fewer than n\n",
    "            while len(uniq) < n:\n",
    "                uniq.append(f\"Option{len(uniq)+1}\")\n",
    "            return uniq[:n]\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                # last resort fallbacks\n",
    "                return [f\"Option{i}\" for i in range(1, n+1)]\n",
    "            time.sleep(backoff)\n",
    "            backoff *= 2\n",
    "\n",
    "def format_choices(correct: str, wrongs: List[str]) -> str:\n",
    "    \"\"\"Format as required MCQ string with A=correct, B/C/D=wrongs.\"\"\"\n",
    "    wrongs = (wrongs + [\"B\", \"C\", \"D\"])[:3]  # ensure length 3\n",
    "    return f\"(A) {correct}\\n(B) {wrongs[0]}\\n(C) {wrongs[1]}\\n(D) {wrongs[2]}\"\n",
    "\n",
    "def add_mcq_choices(df, batch_size: int = 50, max_workers: int = 10):\n",
    "    \"\"\"Add/overwrite df['choices'] using OpenAI for wrong answers. Batch processing with parallel API calls.\"\"\"\n",
    "    questions = df[\"question\"].tolist()\n",
    "    answers = df[\"answer\"].tolist()\n",
    "    n_total = len(questions)\n",
    "    \n",
    "    def process_single(idx, question, answer):\n",
    "        \"\"\"Process a single item and return index + result.\"\"\"\n",
    "        wrongs = generate_distractors(client, question, answer, n=3, model=MODEL_NAME)\n",
    "        return idx, wrongs\n",
    "    \n",
    "    # Process in batches with parallel workers\n",
    "    results = [None] * n_total\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_single, idx, q, a): idx \n",
    "                   for idx, (q, a) in enumerate(zip(questions, answers))}\n",
    "        \n",
    "        # Collect results with progress bar\n",
    "        for future in tqdm(as_completed(futures), total=n_total, desc=\"Generating distractors\"):\n",
    "            idx, wrongs = future.result()\n",
    "            results[idx] = wrongs\n",
    "    \n",
    "    # Format choices\n",
    "    df[\"choices\"] = [\n",
    "        format_choices(corr, w) for corr, w in zip(answers, results)\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "# Example:\n",
    "# df_tmp = df_test.sample(10)\n",
    "# add_mcq_choices(df_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example:\n",
    "# df_tmp = df_test.sample(10)\n",
    "# add_mcq_choices(df_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process df_test in chunks of 100 rows\n",
    "chunk_size = 100\n",
    "df_result_chunks = []\n",
    "\n",
    "for i in tqdm(range(0, len(df_test), chunk_size), desc=\"Processing chunks\"):\n",
    "    df_sub = df_test.iloc[i:i+chunk_size].copy()\n",
    "    df_sub = add_mcq_choices(df_sub)\n",
    "    df_result_chunks.append(df_sub)\n",
    "    print(f\"Processed rows {i} to {min(i+chunk_size, len(df_test))}\")\n",
    "\n",
    "df_test_final = pd.concat(df_result_chunks, ignore_index=True)\n",
    "print(f\"Completed: {len(df_test_final)} rows processed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process df_train in chunks of 100 rows\n",
    "chunk_size = 100\n",
    "df_result_chunks = []\n",
    "\n",
    "for i in tqdm(range(0, len(df_train), chunk_size), desc=\"Processing chunks\"):\n",
    "    df_sub = df_train.iloc[i:i+chunk_size].copy()\n",
    "    df_sub = add_mcq_choices(df_sub)\n",
    "    df_result_chunks.append(df_sub)\n",
    "    print(f\"Processed rows {i} to {min(i+chunk_size, len(df_train))}\")\n",
    "\n",
    "df_train_final = pd.concat(df_result_chunks, ignore_index=True)\n",
    "print(f\"Completed: {len(df_train_final)} rows processed\")\n",
    "df_train_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_DIR = FVQA_DIR / \"parquet\"\n",
    "PARQUET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train_final.to_parquet(PARQUET_DIR / \"train.parquet\", index=False)\n",
    "df_val.to_parquet(PARQUET_DIR / \"val.parquet\", index=False)\n",
    "df_test_final.to_parquet(PARQUET_DIR / \"test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32025c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokens import HF_TOKEN\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder, upload_file\n",
    "from huggingface_hub.utils import disable_progress_bars\n",
    "disable_progress_bars()\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "repo_id = \"JJoy333/RationaleVQA\"\n",
    "create_repo(repo_id=repo_id, repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=str(PARQUET_DIR),\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    path_in_repo=\"FVQA\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519eec96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
